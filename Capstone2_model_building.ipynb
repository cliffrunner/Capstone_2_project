{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I91ns5cnSWfy"
   },
   "source": [
    "# Model Building\n",
    "This notebook has two sections:\n",
    "1. data engineering to prepare data to be model-ready\n",
    "2. machine learning to discover intrinsic correlation between certain disease and behaviors'\n",
    "\n",
    "Here I still use the 2015 Behavior Risk Factor Surveillance System data for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaeTKdXVSWf0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "# from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KT4RzsQ-SWf4"
   },
   "outputs": [],
   "source": [
    "path = \"C:/Users/yao_p/Downloads/behavioral-risk-factor-surveillance-system/2015.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_irOctGeZgKl"
   },
   "source": [
    "In this notebook, I am trying to answer the following questions:\n",
    "+ *__how do behaviors affect mental health (depressive disorder)?__*\n",
    "\n",
    "Among all features provided in the dataset, the following are of great importance for my purpose:\n",
    "+ __behavior features__\n",
    "\n",
    "    _INCOMG. _Composite income category_\n",
    "\n",
    "    MARITAL. _Marriage status_\n",
    "\n",
    "    _AGEG5YR. _Age group_\n",
    "\n",
    "    EDUCA. _Education level_\n",
    "\n",
    "    _PA150R2. _150 min physcial activity category (whether a person get at least 150 min of exercise per week)_\n",
    "\n",
    "    _PA300R2. _300 min physical activity category (whether a person get at least 300 min of exercise per week)_\n",
    "        \n",
    "    _PAREC1. _Aerobic and strenghtening guideline (whether a person meet the aerobic and strenghtening guideline)_\n",
    "\n",
    "    _RFBING5. _Binge driver category_\n",
    "\n",
    "    _RFSMOK3. _Smoking category_\n",
    "    \n",
    "    _BMI5CAT. _BMI category_\n",
    "\n",
    "\n",
    "+ __illness features__\n",
    "    \n",
    "    ADDEPEV2. _Ever been told had depressive disorder?_ \n",
    "    \n",
    "    DIABETE3. _Ever been told had diabetes?_\n",
    "    \n",
    "    CHCKIDNY. _Ever been told had kidney cancer?_\n",
    "    \n",
    "    CHCSCNCR. _Ever been told had skin cancer?_\n",
    "    \n",
    "    CHCOCNCR. _Ever been told had other cancer?_\n",
    "\n",
    "All behavior features are categorical data, there is no continous data involved in the feature.\n",
    "\n",
    "The goal is to use behavoir features to predict diseases. Even though some disease might have more than 2 categories, such as diabetes could be yes, no and boarderline diabetes, for simplicity all diseases only have two status: yes or no. Therefore the problem boils down to a binary category problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qe7A7W9iSWf7"
   },
   "outputs": [],
   "source": [
    "bh_factor = ['_INCOMG','MARITAL','_AGEG5YR','EDUCA','_PA150R2','_PA300R2','_PAREC1','_RFBING5','_RFSMOK3','_BMI5CAT']\n",
    "illness = ['ADDEPEV2','DIABETE3','CHCKIDNY','CHCSCNCR','CHCOCNCR']\n",
    "\n",
    "df_bh = df[bh_factor+illness]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEUf95BRZgKp"
   },
   "source": [
    "From the last notebook (EDA), we know that:\n",
    "1. for many features, categories 7 and 9 mean the respondent refused to answer the question/ didn't knonw the answer to the question. Therefore it should be set as None.\n",
    "\n",
    "2. some features use category 14 to mean the respondent refused to answer the question/ didn't knonw the answer to the question. Therefore it should be set as None.\n",
    "\n",
    "3. for diabete feature(DIABETE3), categories 2,3,4 mean 'yes, but female during pregnancy', 'no', 'no, pre- or border-diabetes'. For simplicity, 2 is re-assigned to as 'yes' (1), and 3 and 4 are re-assigned to as 'no' (2)\n",
    "\n",
    "After data clean, we can drop all null values since in general those values are only a small portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n38SarQeSWf-",
    "outputId": "64937683-a46a-43c7-e712-0c2246610da1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5886: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_bh['_INCOMG'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['MARITAL'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['_AGEG5YR'].replace(to_replace=14, value=np.nan, inplace=True)\n",
    "df_bh['EDUCA'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['_PA150R2'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['_PA300R2'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['_PAREC1'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['_RFBING5'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['_RFSMOK3'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['_BMI5CAT'].replace(to_replace=5, value=np.nan, inplace=True)\n",
    "\n",
    "df_bh['ADDEPEV2'].replace(to_replace=7, value=np.nan, inplace=True)\n",
    "df_bh['ADDEPEV2'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "\n",
    "df_bh['DIABETE3'].replace(to_replace=7, value=np.nan, inplace=True)\n",
    "df_bh['DIABETE3'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "df_bh['DIABETE3'].replace(to_replace=2, value=1, inplace=True)\n",
    "df_bh['DIABETE3'].replace(to_replace=3, value=2, inplace=True)\n",
    "df_bh['DIABETE3'].replace(to_replace=4, value=2, inplace=True)\n",
    "\n",
    "df_bh['CHCKIDNY'].replace(to_replace=7, value=np.nan, inplace=True)\n",
    "df_bh['CHCKIDNY'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "\n",
    "df_bh['CHCSCNCR'].replace(to_replace=7, value=np.nan, inplace=True)\n",
    "df_bh['CHCSCNCR'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "\n",
    "df_bh['CHCOCNCR'].replace(to_replace=7, value=np.nan, inplace=True)\n",
    "df_bh['CHCOCNCR'].replace(to_replace=9, value=np.nan, inplace=True)\n",
    "\n",
    "df_bh.dropna(inplace=True)\n",
    "df_bh.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8_J37QvzZgKu"
   },
   "source": [
    "To better understand each feature, all the numerical codes are changed to phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6PpdFnLSWgD"
   },
   "outputs": [],
   "source": [
    "df_bh.columns = ['income',\n",
    "                'marriage_status',\n",
    "                'age_cat',\n",
    "                'edu',\n",
    "                'exercise_cat150', \n",
    "                'exercise_cat300',\n",
    "                'exercise_guide',\n",
    "                'binge',\n",
    "                'smoke',\n",
    "                'bmi_cat',\n",
    "                'depress_disorder',\n",
    "                'diabetes',\n",
    "                'kidney',\n",
    "                'skin_cancer',\n",
    "                'other_cancer',\n",
    "                ]\n",
    "\n",
    "income_dict = {1:'<15,000',\n",
    "              2:'>15,000 and < 25,000',\n",
    "              3:'>25,000 and < 35,000',\n",
    "              4:'>35,000 and <50,000',\n",
    "              5:'>50,000',\n",
    "              9:\"don't know/not sure/missing\"}\n",
    "\n",
    "smoke_dict = {1:'no',\n",
    "             2:'yes',\n",
    "             9:\"don't know/refused/missing\"}\n",
    "\n",
    "binge_dict = {1:'no',\n",
    "             2:'yes',\n",
    "             9:\"don't know/refused/missing\"}\n",
    "\n",
    "m150_dict = {1:'more than 150 min',\n",
    "            2:'less than 150 min',\n",
    "            3:'0 min',\n",
    "            9:\"don't know/not sure/refused/missing\"}\n",
    "\n",
    "m300_dict = {1:'more than 300 min',\n",
    "            2:'less than 300 min',\n",
    "            3:'0 min',\n",
    "            9:\"don't know/not sure/refused/missing\"}\n",
    "\n",
    "guide_dict = {1:'meet both',\n",
    "            2:'meet aerobic guideline only',\n",
    "            3:'meet strengthening guideline only',\n",
    "            4:'meet neigher',\n",
    "            9:\"don't know/not sure/refused/missing\"}\n",
    "\n",
    "bmi_dict = {1:'underweight',\n",
    "           2:'normal weight',\n",
    "           3:'overweight',\n",
    "           4:'obese',\n",
    "           5:\"don't know/refused/missing\"}\n",
    "\n",
    "marr_dict = {1:'married',\n",
    "            2:'divorced',\n",
    "            3:'widowed',\n",
    "            4:'separated',\n",
    "            5:'never married',\n",
    "            6:'member of an unmarried couple',\n",
    "            9:'refused'}\n",
    "\n",
    "age_dict = {1:'18-24',\n",
    "           2:'25-29',\n",
    "           3:'30-34',\n",
    "           4:'35-39',\n",
    "           5:'40-44',\n",
    "           6:'45-49',\n",
    "           7:'50-54',\n",
    "           8:'55-59',\n",
    "           9:'60-64',\n",
    "           10:'65-69',\n",
    "           11:'70-74',\n",
    "           12:'75-79',\n",
    "           13:'80 and above',\n",
    "           14:\"don't know/refused/missing\"}\n",
    "\n",
    "edu_dict = {1:'never', \n",
    "            2:'elementary', \n",
    "            3:'some high school', \n",
    "            4:'high school grad', \n",
    "            5:'some college', \n",
    "            6:\"college grad\", \n",
    "            9:'refused'}\n",
    "\n",
    "depress_dict = {1:'yes',\n",
    "               2:'no',\n",
    "               7:\"don't know/not sure\",\n",
    "               9:'refused'}\n",
    "\n",
    "diab_dict = {1:'yes',\n",
    "            2:'yes, but female during pregnancy',\n",
    "            3:'no',\n",
    "            4:'no, pre- or border-diabetes',\n",
    "            7:\"don't know/not sure\",\n",
    "            9:'refused'}\n",
    "\n",
    "kidney_dict = {1:'yes',\n",
    "               2:'no',\n",
    "               7:\"don't know/not sure\",\n",
    "               9:'refused'}\n",
    "\n",
    "skin_dict = {1:'yes',\n",
    "            2:'no',\n",
    "            7:\"don't know\",\n",
    "            9:'refused'}\n",
    "\n",
    "other_cancer_dict = {1:'yes',\n",
    "            2:'no',\n",
    "            7:\"don't know\",\n",
    "            9:'refused'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MxuObSWSWgF"
   },
   "outputs": [],
   "source": [
    "def change_label(series, dictionary):\n",
    "    temp = [dictionary[val] for val in series]\n",
    "    return pd.Series(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvqCLHnfSWgI",
    "outputId": "d739ee45-c2e1-4743-86e6-8cb0168e593c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_bh['income'].update(change_label(df_bh['income'], income_dict))\n",
    "df_bh['marriage_status'].update(change_label(df_bh['marriage_status'], marr_dict))\n",
    "df_bh['age_cat'].update(change_label(df_bh['age_cat'], age_dict))\n",
    "df_bh['edu'].update(change_label(df_bh['edu'], edu_dict))\n",
    "df_bh['exercise_cat150'].update(change_label(df_bh['exercise_cat150'], m150_dict))\n",
    "df_bh['exercise_cat300'].update(change_label(df_bh['exercise_cat300'], m300_dict))\n",
    "df_bh['exercise_guide'].update(change_label(df_bh['exercise_guide'], guide_dict))\n",
    "df_bh['binge'].update(change_label(df_bh['binge'], binge_dict))\n",
    "df_bh['smoke'].update(change_label(df_bh['smoke'], smoke_dict))\n",
    "df_bh['bmi_cat'].update(change_label(df_bh['bmi_cat'], bmi_dict))\n",
    "df_bh['depress_disorder'].update(change_label(df_bh['depress_disorder'], depress_dict))\n",
    "df_bh['diabetes'].update(change_label(df_bh['diabetes'], diab_dict))\n",
    "df_bh['kidney'].update(change_label(df_bh['kidney'], kidney_dict))\n",
    "df_bh['skin_cancer'].update(change_label(df_bh['skin_cancer'], skin_dict))\n",
    "df_bh['other_cancer'].update(change_label(df_bh['other_cancer'], other_cancer_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufU_uWN_SWgN"
   },
   "outputs": [],
   "source": [
    "df_bh.to_csv('cat_behavior_vs_depressive_discorder.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XISGRWF5SWgQ"
   },
   "source": [
    "## Use Multiple classifier to predict despressive disorder from behaviors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21677,
     "status": "ok",
     "timestamp": 1547761727993,
     "user": {
      "displayName": "Yao Peng",
      "photoUrl": "",
      "userId": "12020426918915651051"
     },
     "user_tz": 360
    },
    "id": "U5g98KIkSWgR",
    "outputId": "6ee2ee40-2065-442e-e856-02b0b3f33a0a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# from google.colab import files\n",
    "# files.upload('C:\\Users\\ypeng\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21bvjHvLSWgT"
   },
   "outputs": [],
   "source": [
    "read_from_file = True\n",
    "if read_from_file:\n",
    "#     path = '/content/gdrive/My Drive/cat_behavior_vs_depressive_discorder.csv'\n",
    "    path = 'cat_behavior_vs_depressive_discorder.csv'\n",
    "    df_bh = pd.read_csv(path)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1C3eb8cYZgLC"
   },
   "source": [
    "Pick only one disease each time for model training and testing.\n",
    "\n",
    "from EDA, it is easy to see that the majority of respondents do not have a certain disease. Therefore training on the raw data will lead to the data unbalance issue. For instance, for a disease with 90% people free of it, ML models are likely to treat the remaining 10% people who have the disease as noise and therefore are ignored.\n",
    "\n",
    "In this project, both minority upsampling and majority downsampling methods are used to achieve a balance dataset. After data engineering, the number of 'yes' and 'no' are the same in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1547763250135,
     "user": {
      "displayName": "Yao Peng",
      "photoUrl": "",
      "userId": "12020426918915651051"
     },
     "user_tz": 360
    },
    "id": "Ls9QgAKjSWgW",
    "outputId": "b83bd5ce-2e87-48a4-f9a8-433c90fbd340",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X is: (519014, 48)\n"
     ]
    }
   ],
   "source": [
    "disease_label = ['diabetes']\n",
    "disease_labels = ['depress_disorder','diabetes','kidney','skin_cancer','other_cancer']\n",
    "# behavior_labels = ['income','exercise_cat150','exercise_cat300','exercise_guide','bmi_cat']\n",
    "disease_labels.remove(disease_label[0])\n",
    "X = df_bh.drop(columns=disease_labels)\n",
    "# X = df_bh[df_bh['age_cat']>=8]\n",
    "# X = X[behavior_labels+disease_label]\n",
    "\n",
    "temp = X[disease_label[0]].value_counts()\n",
    "X_majority = X[X[disease_label[0]]==2]\n",
    "X_minority = X[X[disease_label[0]]==1]\n",
    "\n",
    "# upsample minority label or downsample majority label\n",
    "upsampled = True\n",
    "if upsampled:\n",
    "    X_minority_upsampled = resample(X_minority,\n",
    "                                    replace=True,\n",
    "                                    n_samples=temp.values[0],\n",
    "                                    random_state=12)\n",
    "    X_upsampled = pd.concat([X_majority, X_minority_upsampled])\n",
    "    X_upsampled = shuffle(X_upsampled)\n",
    "    y = X_upsampled[disease_label[0]]\n",
    "    X = X_upsampled.drop(columns=disease_label)\n",
    "else:\n",
    "    X_majority_downsampled = resample(X_majority,\n",
    "                                    replace=False,\n",
    "                                    n_samples=temp.values[1],\n",
    "                                    random_state=12)\n",
    "    X_downsampled = pd.concat([X_minority, X_majority_downsampled])\n",
    "    X_downsampled = shuffle(X_downsampled)\n",
    "    y = X_downsampled[disease_label[0]]\n",
    "    X = X_downsampled.drop(columns=disease_label)\n",
    "\n",
    "y[y==2.0] = 0\n",
    "# y[y==1.0] = True\n",
    "for column in list(X.columns):\n",
    "    X[column] = X[column].astype('category')\n",
    "X = pd.get_dummies(X)\n",
    "print('size of X is: {}'.format(X.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcWQQX_-Zvtu"
   },
   "source": [
    "Multiple classifiers were originally chosen to compare different model behaviors. Models include:\n",
    "+ Logistic Regression\n",
    "+ Gussian Naive Bayes\n",
    "+ Support Vector Machine\n",
    "\n",
    "Also ensemble methods include:\n",
    "+ Gradient Boosting\n",
    "+ Adaptive Boosting\n",
    "+ Random Forest\n",
    "+ Voting method \n",
    "\n",
    "Deep Nerual Network (DNN) is also used for this classification problem.\n",
    "\n",
    "After model testing, it is concluded that ensemble models in general behave better that single classifiers. Therefore for the rest of model training and testing, I only focus on the ensemble methods.\n",
    "\n",
    "It should be noted that for the purpose of of this project, that is, identify individuals that could have a higher chance of getting certain illness, recall is a better metric for acuracy. Therefore recall is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGdjX2FaSWgY",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "# LR = LogisticRegression()\n",
    "# NB = GaussianNB()\n",
    "# SVC = SVC(probability=True)\n",
    "\n",
    "\n",
    "GB = GradientBoostingClassifier(max_depth=5, n_estimators=200, max_features='auto', verbose=1)\n",
    "AB = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=500)\n",
    "RF = RandomForestClassifier(max_depth=10, n_estimators=500, verbose=1, n_jobs=-1)\n",
    "VC = VotingClassifier(estimators=[('RF',RF),('GB',GB),('AB',AB)], voting='soft', n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZwY1RcfZgLO",
    "outputId": "e405f8a9-b1be-4a87-f784-aa5087d2a65c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   58.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3621            4.90m\n",
      "         2           1.3424            5.38m\n",
      "         3           1.3271            5.56m\n",
      "         4           1.3150            5.32m\n",
      "         5           1.3028            5.40m\n",
      "         6           1.2926            5.39m\n",
      "         7           1.2835            5.56m\n",
      "         8           1.2758            5.54m\n",
      "         9           1.2690            5.46m\n",
      "        10           1.2635            5.36m\n",
      "        20           1.2298            4.92m\n",
      "        30           1.2166            4.53m\n",
      "        40           1.2098            4.21m\n",
      "        50           1.2055            3.92m\n",
      "        60           1.2026            3.60m\n",
      "        70           1.2004            3.29m\n",
      "        80           1.1986            3.00m\n",
      "        90           1.1969            2.73m\n",
      "       100           1.1955            2.45m\n",
      "       200           1.1842            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('RF', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weig...e,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=500, random_state=None))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individual classifier\n",
    "# LR.fit(Xtrain, ytrain)\n",
    "# NB.fit(Xtrain, ytrain)\n",
    "# SVC.fit(Xtrain, ytrain)\n",
    "\n",
    "# ensemble classifier\n",
    "RF.fit(Xtrain, ytrain)\n",
    "AB.fit(Xtrain, ytrain)\n",
    "GB.fit(Xtrain, ytrain)\n",
    "VC.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25596,
     "status": "ok",
     "timestamp": 1546037176707,
     "user": {
      "displayName": "Yao Peng",
      "photoUrl": "",
      "userId": "12020426918915651051"
     },
     "user_tz": 360
    },
    "id": "1MyJVqXiap3L",
    "outputId": "07f704a4-ad4e-4c2a-cd7a-8da6f122ef26",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest recall score (train case): 0.7049171263080772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 500 out of 500 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest recall score (test case): 0.7034825870646766\n"
     ]
    }
   ],
   "source": [
    "ypred = RF.predict(Xtrain)\n",
    "print('random forest recall score (train case): {}'.format(recall_score(ytrain, ypred, pos_label=1)))\n",
    "ypred = RF.predict(Xtest)\n",
    "print('random forest recall score (test case): {}'.format(recall_score(ytest, ypred, pos_label=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3306,
     "status": "ok",
     "timestamp": 1546037143802,
     "user": {
      "displayName": "Yao Peng",
      "photoUrl": "",
      "userId": "12020426918915651051"
     },
     "user_tz": 360
    },
    "id": "4j-i8lFa_guJ",
    "outputId": "b05a3aeb-9db4-4ff4-ecd2-3534b4aa1245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boost recall score (train case): 0.7650690959694402\n",
      "Gradient boost recall score (test case): 0.7628892574166206\n"
     ]
    }
   ],
   "source": [
    "ypred = GB.predict(Xtrain)\n",
    "print('Gradient boost recall score (train case): {}'.format(recall_score(ytrain, ypred, pos_label=1)))\n",
    "ypred = GB.predict(Xtest)\n",
    "print('Gradient boost recall score (test case): {}'.format(recall_score(ytest, ypred, pos_label=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwkrDkRtZgLb",
    "outputId": "301a2f69-29a3-4751-e635-d082498093eb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada boost recall score (train case): 0.7956842090711788\n",
      "Ada boost recall score (test case): 0.7840058964437074\n"
     ]
    }
   ],
   "source": [
    "ypred = AB.predict(Xtrain)\n",
    "print('Ada boost recall score (train case): {}'.format(recall_score(ytrain, ypred, pos_label=1)))\n",
    "ypred = AB.predict(Xtest)\n",
    "print('Ada boost recall score (test case): {}'.format(recall_score(ytest, ypred, pos_label=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmqlE6yIZgLf"
   },
   "outputs": [],
   "source": [
    "ypred = VC.predict(Xtrain)\n",
    "print('Voting classifier recall score (train case): {}'.format(recall_score(ytrain, ypred, pos_label=1)))\n",
    "ypred = VC.predict(Xtest)\n",
    "print('Voting classifier recall score (test case): {}'.format(recall_score(ytest, ypred, pos_label=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hElMEvquUE_"
   },
   "source": [
    "Comparison shows that Adaptive Boosting outperforms any other ensemble methods in general. The worst performing method is random forest, which only gives about 70% recall for both training and testing. Adaptive Boosting, on the other hand, gives 80% recall for training and 78% recall for testing. \n",
    "\n",
    "In the following, more estimators are assigned to adaptive boosting in the hope of improving recall score. However as the result suggests, the recall score slightly drops with more estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lf6JoT6TZgLh"
   },
   "source": [
    "#### Adaboost gives the best accuracy among all ensemble estimators\n",
    "\n",
    "Tune hyperparameters to improve Adaboost scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huIqEnHGZgLi",
    "outputId": "e68133b8-785e-4422-8a0d-aba010079c9c",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=750, random_state=None)"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=750)\n",
    "AB.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iucN0H-xZgLl",
    "outputId": "7cd6c1df-525c-4dab-cd93-dea8ab2a2da7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada boost recall score (train case): 0.7851388895576431\n",
      "Ada boost recall score (test case): 0.773058814448904\n"
     ]
    }
   ],
   "source": [
    "ypred = AB.predict(Xtrain)\n",
    "print('Ada boost recall score (train case): {}'.format(recall_score(ytrain, ypred, pos_label=1)))\n",
    "ypred = AB.predict(Xtest)\n",
    "print('Ada boost recall score (test case): {}'.format(recall_score(ytest, ypred, pos_label=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nc1H8ZDSZgLo",
    "outputId": "769c2e4a-aa7b-47ae-ff50-e316a485d5cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02832284, 0.03258955, 0.03236216, 0.03741614, 0.02966428,\n",
       "       0.0215393 , 0.02458995, 0.01686735, 0.01714279, 0.02846159,\n",
       "       0.02196874, 0.00920721, 0.01159621, 0.01543078, 0.01562289,\n",
       "       0.0145383 , 0.01352698, 0.01405951, 0.01352015, 0.01267613,\n",
       "       0.00960189, 0.0100748 , 0.01151648, 0.0111138 , 0.00041866,\n",
       "       0.01508882, 0.02258565, 0.03367295, 0.02998741, 0.02907443,\n",
       "       0.00729918, 0.025498  , 0.00769413, 0.02492844, 0.02608508,\n",
       "       0.00969476, 0.03340291, 0.02291545, 0.02649462, 0.01541237,\n",
       "       0.02399975, 0.02564311, 0.0262542 , 0.0247857 , 0.0158843 ,\n",
       "       0.03401098, 0.03108809, 0.03467121])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AB.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXBaRZZ8ZgLs"
   },
   "source": [
    "#### ANN model\n",
    "Here ANN is introduced to see whether it will outperform the ensemble classifiers, especially adaptive boosting. After 400 epochs, recall score for training is above 76% and for testing is about 75%. Even though recall score for training is still improving, the testing score stabalizes. This is an indication of overfitting the training data, and therefore the modeling is terminated.\n",
    "\n",
    "ANN in this case has similar perfomance as gradient boosting and voting classifier, and outperforms random forest, but falls behind adaptive boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4852
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3357121,
     "status": "error",
     "timestamp": 1547768032629,
     "user": {
      "displayName": "Yao Peng",
      "photoUrl": "",
      "userId": "12020426918915651051"
     },
     "user_tz": 360
    },
    "id": "57fDQjlHZgLt",
    "outputId": "87fddc77-27df-43e2-f5da-3204e59aa9fd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 415211 samples, validate on 103803 samples\n",
      "Epoch 1/200\n",
      "415211/415211 [==============================] - 13s 31us/step - loss: 0.5971 - recall: 0.6797 - val_loss: 0.5813 - val_recall: 0.6948\n",
      "Epoch 2/200\n",
      " 50000/415211 [==>...........................] - ETA: 1s - loss: 0.5763 - recall: 0.6995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `categorical_crossentropy` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5788 - recall: 0.6974 - val_loss: 0.5799 - val_recall: 0.6952\n",
      "Epoch 3/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5766 - recall: 0.6981 - val_loss: 0.5783 - val_recall: 0.6964\n",
      "Epoch 4/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5746 - recall: 0.7006 - val_loss: 0.5769 - val_recall: 0.6975\n",
      "Epoch 5/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5726 - recall: 0.7017 - val_loss: 0.5750 - val_recall: 0.6985\n",
      "Epoch 6/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5705 - recall: 0.7041 - val_loss: 0.5730 - val_recall: 0.6999\n",
      "Epoch 7/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5684 - recall: 0.7043 - val_loss: 0.5710 - val_recall: 0.7023\n",
      "Epoch 8/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5654 - recall: 0.7067 - val_loss: 0.5692 - val_recall: 0.7019\n",
      "Epoch 9/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5633 - recall: 0.7085 - val_loss: 0.5664 - val_recall: 0.7045\n",
      "Epoch 10/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5609 - recall: 0.7099 - val_loss: 0.5639 - val_recall: 0.7052\n",
      "Epoch 11/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5575 - recall: 0.7123 - val_loss: 0.5612 - val_recall: 0.7097\n",
      "Epoch 12/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5549 - recall: 0.7144 - val_loss: 0.5579 - val_recall: 0.7109\n",
      "Epoch 13/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5524 - recall: 0.7157 - val_loss: 0.5552 - val_recall: 0.7118\n",
      "Epoch 14/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5500 - recall: 0.7172 - val_loss: 0.5530 - val_recall: 0.7160\n",
      "Epoch 15/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5464 - recall: 0.7199 - val_loss: 0.5500 - val_recall: 0.7161\n",
      "Epoch 16/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5429 - recall: 0.7222 - val_loss: 0.5463 - val_recall: 0.7185\n",
      "Epoch 17/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5406 - recall: 0.7235 - val_loss: 0.5459 - val_recall: 0.7182\n",
      "Epoch 18/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5388 - recall: 0.7243 - val_loss: 0.5411 - val_recall: 0.7219\n",
      "Epoch 19/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5357 - recall: 0.7272 - val_loss: 0.5389 - val_recall: 0.7226\n",
      "Epoch 20/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5335 - recall: 0.7283 - val_loss: 0.5371 - val_recall: 0.7237\n",
      "Epoch 21/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5305 - recall: 0.7302 - val_loss: 0.5354 - val_recall: 0.7242\n",
      "Epoch 22/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5291 - recall: 0.7309 - val_loss: 0.5341 - val_recall: 0.7254\n",
      "Epoch 23/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5267 - recall: 0.7326 - val_loss: 0.5315 - val_recall: 0.7278\n",
      "Epoch 24/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5246 - recall: 0.7333 - val_loss: 0.5301 - val_recall: 0.7290\n",
      "Epoch 25/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5227 - recall: 0.7342 - val_loss: 0.5286 - val_recall: 0.7287\n",
      "Epoch 26/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5212 - recall: 0.7355 - val_loss: 0.5262 - val_recall: 0.7298\n",
      "Epoch 27/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5187 - recall: 0.7368 - val_loss: 0.5249 - val_recall: 0.7310\n",
      "Epoch 28/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5173 - recall: 0.7378 - val_loss: 0.5229 - val_recall: 0.7329\n",
      "Epoch 29/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5157 - recall: 0.7384 - val_loss: 0.5214 - val_recall: 0.7335\n",
      "Epoch 30/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5135 - recall: 0.7397 - val_loss: 0.5206 - val_recall: 0.7340\n",
      "Epoch 31/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5125 - recall: 0.7400 - val_loss: 0.5189 - val_recall: 0.7343\n",
      "Epoch 32/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5111 - recall: 0.7410 - val_loss: 0.5180 - val_recall: 0.7352\n",
      "Epoch 33/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5096 - recall: 0.7412 - val_loss: 0.5170 - val_recall: 0.7362\n",
      "Epoch 34/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5082 - recall: 0.7423 - val_loss: 0.5175 - val_recall: 0.7354\n",
      "Epoch 35/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5074 - recall: 0.7431 - val_loss: 0.5146 - val_recall: 0.7368\n",
      "Epoch 36/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5057 - recall: 0.7436 - val_loss: 0.5144 - val_recall: 0.7370\n",
      "Epoch 37/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5042 - recall: 0.7446 - val_loss: 0.5135 - val_recall: 0.7380\n",
      "Epoch 38/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5040 - recall: 0.7443 - val_loss: 0.5120 - val_recall: 0.7375\n",
      "Epoch 39/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5026 - recall: 0.7451 - val_loss: 0.5106 - val_recall: 0.7381\n",
      "Epoch 40/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5019 - recall: 0.7459 - val_loss: 0.5105 - val_recall: 0.7392\n",
      "Epoch 41/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5004 - recall: 0.7466 - val_loss: 0.5108 - val_recall: 0.7397\n",
      "Epoch 42/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.5004 - recall: 0.7462 - val_loss: 0.5095 - val_recall: 0.7402\n",
      "Epoch 43/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4984 - recall: 0.7476 - val_loss: 0.5074 - val_recall: 0.7400\n",
      "Epoch 44/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4980 - recall: 0.7473 - val_loss: 0.5064 - val_recall: 0.7417\n",
      "Epoch 45/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4974 - recall: 0.7480 - val_loss: 0.5084 - val_recall: 0.7412\n",
      "Epoch 46/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4954 - recall: 0.7485 - val_loss: 0.5076 - val_recall: 0.7398\n",
      "Epoch 47/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4955 - recall: 0.7487 - val_loss: 0.5071 - val_recall: 0.7405\n",
      "Epoch 48/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4950 - recall: 0.7487 - val_loss: 0.5069 - val_recall: 0.7410\n",
      "Epoch 49/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4942 - recall: 0.7496 - val_loss: 0.5059 - val_recall: 0.7420\n",
      "Epoch 50/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4932 - recall: 0.7501 - val_loss: 0.5037 - val_recall: 0.7431\n",
      "Epoch 51/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4926 - recall: 0.7501 - val_loss: 0.5043 - val_recall: 0.7421\n",
      "Epoch 52/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4918 - recall: 0.7504 - val_loss: 0.5030 - val_recall: 0.7426\n",
      "Epoch 53/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4910 - recall: 0.7512 - val_loss: 0.5028 - val_recall: 0.7437\n",
      "Epoch 54/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4903 - recall: 0.7520 - val_loss: 0.5028 - val_recall: 0.7418\n",
      "Epoch 55/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4904 - recall: 0.7510 - val_loss: 0.5016 - val_recall: 0.7434\n",
      "Epoch 56/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4899 - recall: 0.7519 - val_loss: 0.5013 - val_recall: 0.7435\n",
      "Epoch 57/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4886 - recall: 0.7518 - val_loss: 0.5023 - val_recall: 0.7429\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4885 - recall: 0.7528 - val_loss: 0.5004 - val_recall: 0.7443\n",
      "Epoch 59/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4883 - recall: 0.7523 - val_loss: 0.5013 - val_recall: 0.7443\n",
      "Epoch 60/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4874 - recall: 0.7530 - val_loss: 0.5010 - val_recall: 0.7448\n",
      "Epoch 61/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4871 - recall: 0.7529 - val_loss: 0.5009 - val_recall: 0.7444\n",
      "Epoch 62/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4867 - recall: 0.7532 - val_loss: 0.5013 - val_recall: 0.7440\n",
      "Epoch 63/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4851 - recall: 0.7539 - val_loss: 0.5002 - val_recall: 0.7439\n",
      "Epoch 64/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4852 - recall: 0.7539 - val_loss: 0.4994 - val_recall: 0.7454\n",
      "Epoch 65/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4853 - recall: 0.7537 - val_loss: 0.4985 - val_recall: 0.7462\n",
      "Epoch 66/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4844 - recall: 0.7545 - val_loss: 0.5010 - val_recall: 0.7444\n",
      "Epoch 67/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4846 - recall: 0.7538 - val_loss: 0.4983 - val_recall: 0.7458\n",
      "Epoch 68/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4837 - recall: 0.7547 - val_loss: 0.4985 - val_recall: 0.7457\n",
      "Epoch 69/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4836 - recall: 0.7543 - val_loss: 0.4999 - val_recall: 0.7449\n",
      "Epoch 70/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4828 - recall: 0.7550 - val_loss: 0.4977 - val_recall: 0.7460\n",
      "Epoch 71/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4827 - recall: 0.7554 - val_loss: 0.4969 - val_recall: 0.7461\n",
      "Epoch 72/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4827 - recall: 0.7547 - val_loss: 0.4967 - val_recall: 0.7466\n",
      "Epoch 73/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4822 - recall: 0.7552 - val_loss: 0.4980 - val_recall: 0.7455\n",
      "Epoch 74/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4812 - recall: 0.7559 - val_loss: 0.4967 - val_recall: 0.7462\n",
      "Epoch 75/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4812 - recall: 0.7560 - val_loss: 0.4963 - val_recall: 0.7466\n",
      "Epoch 76/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4806 - recall: 0.7563 - val_loss: 0.4966 - val_recall: 0.7467\n",
      "Epoch 77/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4803 - recall: 0.7563 - val_loss: 0.4953 - val_recall: 0.7467\n",
      "Epoch 78/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4805 - recall: 0.7564 - val_loss: 0.4955 - val_recall: 0.7467\n",
      "Epoch 79/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4793 - recall: 0.7565 - val_loss: 0.4974 - val_recall: 0.7454\n",
      "Epoch 80/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4797 - recall: 0.7570 - val_loss: 0.4959 - val_recall: 0.7472\n",
      "Epoch 81/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4795 - recall: 0.7560 - val_loss: 0.4953 - val_recall: 0.7480\n",
      "Epoch 82/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4790 - recall: 0.7573 - val_loss: 0.4951 - val_recall: 0.7473\n",
      "Epoch 83/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4782 - recall: 0.7575 - val_loss: 0.4952 - val_recall: 0.7474\n",
      "Epoch 84/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4780 - recall: 0.7572 - val_loss: 0.4962 - val_recall: 0.7467\n",
      "Epoch 85/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4780 - recall: 0.7577 - val_loss: 0.4954 - val_recall: 0.7475\n",
      "Epoch 86/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4771 - recall: 0.7583 - val_loss: 0.4954 - val_recall: 0.7476\n",
      "Epoch 87/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4771 - recall: 0.7579 - val_loss: 0.4945 - val_recall: 0.7484\n",
      "Epoch 88/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4775 - recall: 0.7580 - val_loss: 0.4950 - val_recall: 0.7486\n",
      "Epoch 89/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4767 - recall: 0.7578 - val_loss: 0.4958 - val_recall: 0.7485\n",
      "Epoch 90/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4767 - recall: 0.7577 - val_loss: 0.4954 - val_recall: 0.7472\n",
      "Epoch 91/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4764 - recall: 0.7584 - val_loss: 0.4959 - val_recall: 0.7478\n",
      "Epoch 92/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4763 - recall: 0.7582 - val_loss: 0.4959 - val_recall: 0.7481\n",
      "Epoch 93/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4761 - recall: 0.7585 - val_loss: 0.4949 - val_recall: 0.7485\n",
      "Epoch 94/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4759 - recall: 0.7589 - val_loss: 0.4951 - val_recall: 0.7481\n",
      "Epoch 95/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4754 - recall: 0.7585 - val_loss: 0.4935 - val_recall: 0.7479\n",
      "Epoch 96/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4751 - recall: 0.7591 - val_loss: 0.4937 - val_recall: 0.7484\n",
      "Epoch 97/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4743 - recall: 0.7596 - val_loss: 0.4941 - val_recall: 0.7483\n",
      "Epoch 98/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4749 - recall: 0.7588 - val_loss: 0.4953 - val_recall: 0.7476\n",
      "Epoch 99/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4750 - recall: 0.7589 - val_loss: 0.4940 - val_recall: 0.7487\n",
      "Epoch 100/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4744 - recall: 0.7593 - val_loss: 0.4941 - val_recall: 0.7478\n",
      "Epoch 101/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4742 - recall: 0.7592 - val_loss: 0.4943 - val_recall: 0.7481\n",
      "Epoch 102/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4743 - recall: 0.7591 - val_loss: 0.4938 - val_recall: 0.7485\n",
      "Epoch 103/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4737 - recall: 0.7596 - val_loss: 0.4941 - val_recall: 0.7492\n",
      "Epoch 104/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4733 - recall: 0.7595 - val_loss: 0.4938 - val_recall: 0.7482\n",
      "Epoch 105/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4731 - recall: 0.7598 - val_loss: 0.4934 - val_recall: 0.7488\n",
      "Epoch 106/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4735 - recall: 0.7595 - val_loss: 0.4940 - val_recall: 0.7496\n",
      "Epoch 107/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4737 - recall: 0.7602 - val_loss: 0.4935 - val_recall: 0.7490\n",
      "Epoch 108/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4734 - recall: 0.7593 - val_loss: 0.4931 - val_recall: 0.7485\n",
      "Epoch 109/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4730 - recall: 0.7600 - val_loss: 0.4934 - val_recall: 0.7483\n",
      "Epoch 110/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4725 - recall: 0.7601 - val_loss: 0.4925 - val_recall: 0.7495\n",
      "Epoch 111/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4722 - recall: 0.7599 - val_loss: 0.4938 - val_recall: 0.7488\n",
      "Epoch 112/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4720 - recall: 0.7600 - val_loss: 0.4928 - val_recall: 0.7496\n",
      "Epoch 113/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4721 - recall: 0.7603 - val_loss: 0.4926 - val_recall: 0.7493\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4719 - recall: 0.7597 - val_loss: 0.4927 - val_recall: 0.7498\n",
      "Epoch 115/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4717 - recall: 0.7601 - val_loss: 0.4922 - val_recall: 0.7488\n",
      "Epoch 116/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4714 - recall: 0.7606 - val_loss: 0.4939 - val_recall: 0.7491\n",
      "Epoch 117/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4712 - recall: 0.7602 - val_loss: 0.4946 - val_recall: 0.7485\n",
      "Epoch 118/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4716 - recall: 0.7608 - val_loss: 0.4932 - val_recall: 0.7495\n",
      "Epoch 119/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4707 - recall: 0.7607 - val_loss: 0.4930 - val_recall: 0.7493\n",
      "Epoch 120/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4708 - recall: 0.7607 - val_loss: 0.4932 - val_recall: 0.7499\n",
      "Epoch 121/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4709 - recall: 0.7607 - val_loss: 0.4937 - val_recall: 0.7487\n",
      "Epoch 122/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4703 - recall: 0.7608 - val_loss: 0.4930 - val_recall: 0.7491\n",
      "Epoch 123/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4704 - recall: 0.7604 - val_loss: 0.4919 - val_recall: 0.7503\n",
      "Epoch 124/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4704 - recall: 0.7607 - val_loss: 0.4920 - val_recall: 0.7501\n",
      "Epoch 125/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4702 - recall: 0.7610 - val_loss: 0.4915 - val_recall: 0.7499\n",
      "Epoch 126/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4701 - recall: 0.7616 - val_loss: 0.4912 - val_recall: 0.7502\n",
      "Epoch 127/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4695 - recall: 0.7615 - val_loss: 0.4923 - val_recall: 0.7505\n",
      "Epoch 128/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4698 - recall: 0.7613 - val_loss: 0.4925 - val_recall: 0.7505\n",
      "Epoch 129/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4697 - recall: 0.7615 - val_loss: 0.4912 - val_recall: 0.7501\n",
      "Epoch 130/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4699 - recall: 0.7616 - val_loss: 0.4923 - val_recall: 0.7507\n",
      "Epoch 131/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4694 - recall: 0.7615 - val_loss: 0.4913 - val_recall: 0.7499\n",
      "Epoch 132/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4690 - recall: 0.7618 - val_loss: 0.4915 - val_recall: 0.7507\n",
      "Epoch 133/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4695 - recall: 0.7619 - val_loss: 0.4918 - val_recall: 0.7491\n",
      "Epoch 134/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4689 - recall: 0.7622 - val_loss: 0.4928 - val_recall: 0.7496\n",
      "Epoch 135/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4690 - recall: 0.7619 - val_loss: 0.4913 - val_recall: 0.7510\n",
      "Epoch 136/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4687 - recall: 0.7613 - val_loss: 0.4914 - val_recall: 0.7504\n",
      "Epoch 137/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4690 - recall: 0.7617 - val_loss: 0.4926 - val_recall: 0.7509\n",
      "Epoch 138/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4681 - recall: 0.7623 - val_loss: 0.4906 - val_recall: 0.7505\n",
      "Epoch 139/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4688 - recall: 0.7618 - val_loss: 0.4907 - val_recall: 0.7502\n",
      "Epoch 140/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4685 - recall: 0.7620 - val_loss: 0.4910 - val_recall: 0.7509\n",
      "Epoch 141/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4688 - recall: 0.7621 - val_loss: 0.4931 - val_recall: 0.7504\n",
      "Epoch 142/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4676 - recall: 0.7623 - val_loss: 0.4921 - val_recall: 0.7505\n",
      "Epoch 143/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4679 - recall: 0.7621 - val_loss: 0.4912 - val_recall: 0.7501\n",
      "Epoch 144/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4683 - recall: 0.7617 - val_loss: 0.4917 - val_recall: 0.7505\n",
      "Epoch 145/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4679 - recall: 0.7621 - val_loss: 0.4903 - val_recall: 0.7505\n",
      "Epoch 146/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4677 - recall: 0.7622 - val_loss: 0.4917 - val_recall: 0.7493\n",
      "Epoch 147/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4671 - recall: 0.7623 - val_loss: 0.4910 - val_recall: 0.7510\n",
      "Epoch 148/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4674 - recall: 0.7624 - val_loss: 0.4906 - val_recall: 0.7505\n",
      "Epoch 149/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4671 - recall: 0.7624 - val_loss: 0.4903 - val_recall: 0.7504\n",
      "Epoch 150/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4681 - recall: 0.7623 - val_loss: 0.4902 - val_recall: 0.7512\n",
      "Epoch 151/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4675 - recall: 0.7627 - val_loss: 0.4906 - val_recall: 0.7509\n",
      "Epoch 152/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4670 - recall: 0.7625 - val_loss: 0.4906 - val_recall: 0.7506\n",
      "Epoch 153/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4666 - recall: 0.7627 - val_loss: 0.4916 - val_recall: 0.7498\n",
      "Epoch 154/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4670 - recall: 0.7628 - val_loss: 0.4908 - val_recall: 0.7512\n",
      "Epoch 155/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4665 - recall: 0.7626 - val_loss: 0.4898 - val_recall: 0.7512\n",
      "Epoch 156/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4667 - recall: 0.7626 - val_loss: 0.4904 - val_recall: 0.7507\n",
      "Epoch 157/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4669 - recall: 0.7627 - val_loss: 0.4917 - val_recall: 0.7505\n",
      "Epoch 158/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4669 - recall: 0.7629 - val_loss: 0.4912 - val_recall: 0.7513\n",
      "Epoch 159/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4661 - recall: 0.7636 - val_loss: 0.4910 - val_recall: 0.7501\n",
      "Epoch 160/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4662 - recall: 0.7632 - val_loss: 0.4908 - val_recall: 0.7506\n",
      "Epoch 161/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4666 - recall: 0.7626 - val_loss: 0.4911 - val_recall: 0.7505\n",
      "Epoch 162/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4659 - recall: 0.7630 - val_loss: 0.4917 - val_recall: 0.7510\n",
      "Epoch 163/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4662 - recall: 0.7630 - val_loss: 0.4899 - val_recall: 0.7512\n",
      "Epoch 164/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4658 - recall: 0.7635 - val_loss: 0.4910 - val_recall: 0.7517\n",
      "Epoch 165/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4657 - recall: 0.7631 - val_loss: 0.4917 - val_recall: 0.7508\n",
      "Epoch 166/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4661 - recall: 0.7628 - val_loss: 0.4906 - val_recall: 0.7501\n",
      "Epoch 167/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4654 - recall: 0.7634 - val_loss: 0.4913 - val_recall: 0.7507\n",
      "Epoch 168/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4653 - recall: 0.7636 - val_loss: 0.4901 - val_recall: 0.7503\n",
      "Epoch 169/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4655 - recall: 0.7630 - val_loss: 0.4903 - val_recall: 0.7514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4656 - recall: 0.7635 - val_loss: 0.4898 - val_recall: 0.7513\n",
      "Epoch 171/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4655 - recall: 0.7630 - val_loss: 0.4902 - val_recall: 0.7507\n",
      "Epoch 172/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4648 - recall: 0.7630 - val_loss: 0.4897 - val_recall: 0.7506\n",
      "Epoch 173/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4652 - recall: 0.7636 - val_loss: 0.4902 - val_recall: 0.7509\n",
      "Epoch 174/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4643 - recall: 0.7637 - val_loss: 0.4905 - val_recall: 0.7509\n",
      "Epoch 175/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4648 - recall: 0.7633 - val_loss: 0.4903 - val_recall: 0.7513\n",
      "Epoch 176/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4651 - recall: 0.7637 - val_loss: 0.4898 - val_recall: 0.7516\n",
      "Epoch 177/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4644 - recall: 0.7642 - val_loss: 0.4917 - val_recall: 0.7506\n",
      "Epoch 178/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4651 - recall: 0.7634 - val_loss: 0.4912 - val_recall: 0.7505\n",
      "Epoch 179/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4642 - recall: 0.7642 - val_loss: 0.4910 - val_recall: 0.7513\n",
      "Epoch 180/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4646 - recall: 0.7640 - val_loss: 0.4914 - val_recall: 0.7504\n",
      "Epoch 181/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4645 - recall: 0.7639 - val_loss: 0.4907 - val_recall: 0.7511\n",
      "Epoch 182/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4644 - recall: 0.7642 - val_loss: 0.4916 - val_recall: 0.7518\n",
      "Epoch 183/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4642 - recall: 0.7642 - val_loss: 0.4901 - val_recall: 0.7512\n",
      "Epoch 184/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4649 - recall: 0.7637 - val_loss: 0.4907 - val_recall: 0.7521\n",
      "Epoch 185/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4641 - recall: 0.7643 - val_loss: 0.4915 - val_recall: 0.7512\n",
      "Epoch 186/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4644 - recall: 0.7640 - val_loss: 0.4904 - val_recall: 0.7509\n",
      "Epoch 187/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4644 - recall: 0.7637 - val_loss: 0.4907 - val_recall: 0.7517\n",
      "Epoch 188/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4642 - recall: 0.7637 - val_loss: 0.4922 - val_recall: 0.7511\n",
      "Epoch 189/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4639 - recall: 0.7635 - val_loss: 0.4896 - val_recall: 0.7516\n",
      "Epoch 190/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4639 - recall: 0.7637 - val_loss: 0.4917 - val_recall: 0.7522\n",
      "Epoch 191/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4646 - recall: 0.7637 - val_loss: 0.4913 - val_recall: 0.7513\n",
      "Epoch 192/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4637 - recall: 0.7638 - val_loss: 0.4901 - val_recall: 0.7511\n",
      "Epoch 193/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4640 - recall: 0.7639 - val_loss: 0.4907 - val_recall: 0.7513\n",
      "Epoch 194/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4637 - recall: 0.7643 - val_loss: 0.4898 - val_recall: 0.7525\n",
      "Epoch 195/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4638 - recall: 0.7641 - val_loss: 0.4912 - val_recall: 0.7520\n",
      "Epoch 196/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4635 - recall: 0.7643 - val_loss: 0.4897 - val_recall: 0.7519\n",
      "Epoch 197/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4639 - recall: 0.7636 - val_loss: 0.4912 - val_recall: 0.7519\n",
      "Epoch 198/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4637 - recall: 0.7642 - val_loss: 0.4888 - val_recall: 0.7520\n",
      "Epoch 199/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4634 - recall: 0.7642 - val_loss: 0.4893 - val_recall: 0.7523\n",
      "Epoch 200/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4632 - recall: 0.7641 - val_loss: 0.4901 - val_recall: 0.7522\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "# keras does not have recall and precision as metrics\n",
    "# therefore these two metrics are defined below.\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "y = pd.get_dummies(y)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "def ANN_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, activation='relu', input_dim=Xtrain.shape[1]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[recall])\n",
    "\n",
    "    return model\n",
    "\n",
    "ANN = ANN_model()\n",
    "\n",
    "early_stop = [EarlyStopping(monitor='categorical_crossentropy', min_delta=0, patience=3, verbose=1, mode='auto')]\n",
    "\n",
    "# ANN\n",
    "history = ANN.fit(Xtrain, ytrain, validation_data=(Xtest, ytest), epochs=200, batch_size=10000, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 415211 samples, validate on 103803 samples\n",
      "Epoch 1/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4631 - recall: 0.7645 - val_loss: 0.4903 - val_recall: 0.7515\n",
      "Epoch 2/200\n",
      " 50000/415211 [==>...........................] - ETA: 1s - loss: 0.4606 - recall: 0.7669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yao_p\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `categorical_crossentropy` which is not available. Available metrics are: val_loss,val_recall,loss,recall\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4629 - recall: 0.7647 - val_loss: 0.4890 - val_recall: 0.7523\n",
      "Epoch 3/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4633 - recall: 0.7641 - val_loss: 0.4899 - val_recall: 0.7514\n",
      "Epoch 4/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4635 - recall: 0.7642 - val_loss: 0.4900 - val_recall: 0.7514\n",
      "Epoch 5/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4631 - recall: 0.7644 - val_loss: 0.4891 - val_recall: 0.7515\n",
      "Epoch 6/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4624 - recall: 0.7651 - val_loss: 0.4910 - val_recall: 0.7515\n",
      "Epoch 7/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4632 - recall: 0.7648 - val_loss: 0.4905 - val_recall: 0.7514\n",
      "Epoch 8/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4627 - recall: 0.7641 - val_loss: 0.4890 - val_recall: 0.7511\n",
      "Epoch 9/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4629 - recall: 0.7648 - val_loss: 0.4894 - val_recall: 0.7520\n",
      "Epoch 10/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4625 - recall: 0.7648 - val_loss: 0.4915 - val_recall: 0.7511\n",
      "Epoch 11/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4625 - recall: 0.7649 - val_loss: 0.4908 - val_recall: 0.7516\n",
      "Epoch 12/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4620 - recall: 0.7655 - val_loss: 0.4900 - val_recall: 0.7520\n",
      "Epoch 13/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4624 - recall: 0.7645 - val_loss: 0.4915 - val_recall: 0.7517\n",
      "Epoch 14/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4620 - recall: 0.7651 - val_loss: 0.4907 - val_recall: 0.7508\n",
      "Epoch 15/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4622 - recall: 0.7649 - val_loss: 0.4910 - val_recall: 0.7519\n",
      "Epoch 16/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4623 - recall: 0.7648 - val_loss: 0.4913 - val_recall: 0.7517\n",
      "Epoch 17/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4623 - recall: 0.7647 - val_loss: 0.4889 - val_recall: 0.7523\n",
      "Epoch 18/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4624 - recall: 0.7649 - val_loss: 0.4908 - val_recall: 0.7514\n",
      "Epoch 19/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4622 - recall: 0.7648 - val_loss: 0.4886 - val_recall: 0.7526\n",
      "Epoch 20/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4617 - recall: 0.7653 - val_loss: 0.4899 - val_recall: 0.7518\n",
      "Epoch 21/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4616 - recall: 0.7651 - val_loss: 0.4896 - val_recall: 0.7517\n",
      "Epoch 22/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4619 - recall: 0.7650 - val_loss: 0.4904 - val_recall: 0.7522\n",
      "Epoch 23/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4616 - recall: 0.7651 - val_loss: 0.4895 - val_recall: 0.7525\n",
      "Epoch 24/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4613 - recall: 0.7652 - val_loss: 0.4892 - val_recall: 0.7520\n",
      "Epoch 25/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4614 - recall: 0.7650 - val_loss: 0.4908 - val_recall: 0.7516\n",
      "Epoch 26/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4623 - recall: 0.7646 - val_loss: 0.4901 - val_recall: 0.7524\n",
      "Epoch 27/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4617 - recall: 0.7648 - val_loss: 0.4914 - val_recall: 0.7517\n",
      "Epoch 28/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4612 - recall: 0.7657 - val_loss: 0.4896 - val_recall: 0.7524\n",
      "Epoch 29/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4618 - recall: 0.7653 - val_loss: 0.4894 - val_recall: 0.7525\n",
      "Epoch 30/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4616 - recall: 0.7651 - val_loss: 0.4897 - val_recall: 0.7517\n",
      "Epoch 31/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4615 - recall: 0.7650 - val_loss: 0.4898 - val_recall: 0.7523\n",
      "Epoch 32/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4615 - recall: 0.7649 - val_loss: 0.4905 - val_recall: 0.7515\n",
      "Epoch 33/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4609 - recall: 0.7653 - val_loss: 0.4904 - val_recall: 0.7523\n",
      "Epoch 34/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4608 - recall: 0.7654 - val_loss: 0.4901 - val_recall: 0.7518\n",
      "Epoch 35/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4617 - recall: 0.7650 - val_loss: 0.4893 - val_recall: 0.7518\n",
      "Epoch 36/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4612 - recall: 0.7651 - val_loss: 0.4900 - val_recall: 0.7517\n",
      "Epoch 37/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4616 - recall: 0.7653 - val_loss: 0.4897 - val_recall: 0.7524\n",
      "Epoch 38/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4611 - recall: 0.7652 - val_loss: 0.4893 - val_recall: 0.7522\n",
      "Epoch 39/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4608 - recall: 0.7655 - val_loss: 0.4895 - val_recall: 0.7518\n",
      "Epoch 40/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4612 - recall: 0.7654 - val_loss: 0.4905 - val_recall: 0.7516\n",
      "Epoch 41/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4609 - recall: 0.7652 - val_loss: 0.4901 - val_recall: 0.7508\n",
      "Epoch 42/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4610 - recall: 0.7656 - val_loss: 0.4898 - val_recall: 0.7519\n",
      "Epoch 43/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4614 - recall: 0.7652 - val_loss: 0.4900 - val_recall: 0.7520\n",
      "Epoch 44/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4613 - recall: 0.7650 - val_loss: 0.4894 - val_recall: 0.7517\n",
      "Epoch 45/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4614 - recall: 0.7649 - val_loss: 0.4886 - val_recall: 0.7525\n",
      "Epoch 46/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4604 - recall: 0.7656 - val_loss: 0.4896 - val_recall: 0.7521\n",
      "Epoch 47/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4609 - recall: 0.7652 - val_loss: 0.4894 - val_recall: 0.7519\n",
      "Epoch 48/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4604 - recall: 0.7658 - val_loss: 0.4897 - val_recall: 0.7523\n",
      "Epoch 49/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4603 - recall: 0.7657 - val_loss: 0.4902 - val_recall: 0.7521\n",
      "Epoch 50/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4605 - recall: 0.7657 - val_loss: 0.4886 - val_recall: 0.7519\n",
      "Epoch 51/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4607 - recall: 0.7654 - val_loss: 0.4891 - val_recall: 0.7517\n",
      "Epoch 52/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4608 - recall: 0.7656 - val_loss: 0.4896 - val_recall: 0.7521\n",
      "Epoch 53/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4604 - recall: 0.7659 - val_loss: 0.4895 - val_recall: 0.7525\n",
      "Epoch 54/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4602 - recall: 0.7659 - val_loss: 0.4902 - val_recall: 0.7520\n",
      "Epoch 55/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4604 - recall: 0.7662 - val_loss: 0.4892 - val_recall: 0.7522\n",
      "Epoch 56/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4604 - recall: 0.7656 - val_loss: 0.4900 - val_recall: 0.7519\n",
      "Epoch 57/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4600 - recall: 0.7656 - val_loss: 0.4897 - val_recall: 0.7526\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4601 - recall: 0.7654 - val_loss: 0.4912 - val_recall: 0.7515\n",
      "Epoch 59/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4600 - recall: 0.7653 - val_loss: 0.4901 - val_recall: 0.7520\n",
      "Epoch 60/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4596 - recall: 0.7662 - val_loss: 0.4907 - val_recall: 0.7524\n",
      "Epoch 61/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4597 - recall: 0.7663 - val_loss: 0.4906 - val_recall: 0.7515\n",
      "Epoch 62/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4599 - recall: 0.7661 - val_loss: 0.4901 - val_recall: 0.7525\n",
      "Epoch 63/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4601 - recall: 0.7655 - val_loss: 0.4908 - val_recall: 0.7516\n",
      "Epoch 64/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4598 - recall: 0.7662 - val_loss: 0.4893 - val_recall: 0.7522\n",
      "Epoch 65/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4598 - recall: 0.7660 - val_loss: 0.4896 - val_recall: 0.7522\n",
      "Epoch 66/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4596 - recall: 0.7660 - val_loss: 0.4898 - val_recall: 0.7523\n",
      "Epoch 67/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4600 - recall: 0.7659 - val_loss: 0.4900 - val_recall: 0.7519\n",
      "Epoch 68/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4600 - recall: 0.7657 - val_loss: 0.4895 - val_recall: 0.7526\n",
      "Epoch 69/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4600 - recall: 0.7652 - val_loss: 0.4898 - val_recall: 0.7518\n",
      "Epoch 70/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4597 - recall: 0.7661 - val_loss: 0.4911 - val_recall: 0.7518\n",
      "Epoch 71/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4595 - recall: 0.7660 - val_loss: 0.4903 - val_recall: 0.7529\n",
      "Epoch 72/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4595 - recall: 0.7659 - val_loss: 0.4900 - val_recall: 0.7525\n",
      "Epoch 73/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4596 - recall: 0.7660 - val_loss: 0.4899 - val_recall: 0.7525\n",
      "Epoch 74/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4595 - recall: 0.7663 - val_loss: 0.4908 - val_recall: 0.7517\n",
      "Epoch 75/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4591 - recall: 0.7663 - val_loss: 0.4895 - val_recall: 0.7520\n",
      "Epoch 76/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4597 - recall: 0.7660 - val_loss: 0.4894 - val_recall: 0.7518\n",
      "Epoch 77/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4599 - recall: 0.7657 - val_loss: 0.4893 - val_recall: 0.7519\n",
      "Epoch 78/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4591 - recall: 0.7661 - val_loss: 0.4890 - val_recall: 0.7518\n",
      "Epoch 79/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4589 - recall: 0.7664 - val_loss: 0.4883 - val_recall: 0.7520\n",
      "Epoch 80/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4593 - recall: 0.7656 - val_loss: 0.4897 - val_recall: 0.7521\n",
      "Epoch 81/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4599 - recall: 0.7660 - val_loss: 0.4896 - val_recall: 0.7518\n",
      "Epoch 82/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4595 - recall: 0.7659 - val_loss: 0.4901 - val_recall: 0.7518\n",
      "Epoch 83/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4590 - recall: 0.7661 - val_loss: 0.4901 - val_recall: 0.7516\n",
      "Epoch 84/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4592 - recall: 0.7658 - val_loss: 0.4891 - val_recall: 0.7527\n",
      "Epoch 85/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4588 - recall: 0.7668 - val_loss: 0.4898 - val_recall: 0.7524\n",
      "Epoch 86/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4592 - recall: 0.7660 - val_loss: 0.4894 - val_recall: 0.7525\n",
      "Epoch 87/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4592 - recall: 0.7660 - val_loss: 0.4900 - val_recall: 0.7511\n",
      "Epoch 88/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4589 - recall: 0.7664 - val_loss: 0.4889 - val_recall: 0.7531\n",
      "Epoch 89/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4589 - recall: 0.7667 - val_loss: 0.4912 - val_recall: 0.7522\n",
      "Epoch 90/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4589 - recall: 0.7662 - val_loss: 0.4912 - val_recall: 0.7520\n",
      "Epoch 91/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4589 - recall: 0.7666 - val_loss: 0.4897 - val_recall: 0.7522\n",
      "Epoch 92/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4594 - recall: 0.7656 - val_loss: 0.4900 - val_recall: 0.7519\n",
      "Epoch 93/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4586 - recall: 0.7665 - val_loss: 0.4912 - val_recall: 0.7523\n",
      "Epoch 94/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4586 - recall: 0.7662 - val_loss: 0.4902 - val_recall: 0.7517\n",
      "Epoch 95/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4592 - recall: 0.7665 - val_loss: 0.4899 - val_recall: 0.7518\n",
      "Epoch 96/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4587 - recall: 0.7667 - val_loss: 0.4902 - val_recall: 0.7519\n",
      "Epoch 97/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4587 - recall: 0.7666 - val_loss: 0.4893 - val_recall: 0.7519\n",
      "Epoch 98/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4590 - recall: 0.7659 - val_loss: 0.4894 - val_recall: 0.7523\n",
      "Epoch 99/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4584 - recall: 0.7663 - val_loss: 0.4906 - val_recall: 0.7520\n",
      "Epoch 100/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4593 - recall: 0.7663 - val_loss: 0.4898 - val_recall: 0.7518\n",
      "Epoch 101/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4586 - recall: 0.7664 - val_loss: 0.4885 - val_recall: 0.7526\n",
      "Epoch 102/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4586 - recall: 0.7664 - val_loss: 0.4906 - val_recall: 0.7521\n",
      "Epoch 103/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4582 - recall: 0.7667 - val_loss: 0.4910 - val_recall: 0.7517\n",
      "Epoch 104/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4585 - recall: 0.7660 - val_loss: 0.4903 - val_recall: 0.7521\n",
      "Epoch 105/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4589 - recall: 0.7666 - val_loss: 0.4906 - val_recall: 0.7518\n",
      "Epoch 106/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4581 - recall: 0.7667 - val_loss: 0.4902 - val_recall: 0.7527\n",
      "Epoch 107/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4585 - recall: 0.7663 - val_loss: 0.4904 - val_recall: 0.7523\n",
      "Epoch 108/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4584 - recall: 0.7661 - val_loss: 0.4903 - val_recall: 0.7515\n",
      "Epoch 109/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4585 - recall: 0.7670 - val_loss: 0.4886 - val_recall: 0.7523\n",
      "Epoch 110/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4586 - recall: 0.7666 - val_loss: 0.4895 - val_recall: 0.7524\n",
      "Epoch 111/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4583 - recall: 0.7662 - val_loss: 0.4897 - val_recall: 0.7517\n",
      "Epoch 112/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4582 - recall: 0.7667 - val_loss: 0.4915 - val_recall: 0.7521\n",
      "Epoch 113/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4582 - recall: 0.7667 - val_loss: 0.4899 - val_recall: 0.7526\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4584 - recall: 0.7666 - val_loss: 0.4900 - val_recall: 0.7526\n",
      "Epoch 115/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4582 - recall: 0.7666 - val_loss: 0.4891 - val_recall: 0.7523\n",
      "Epoch 116/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4581 - recall: 0.7667 - val_loss: 0.4905 - val_recall: 0.7529\n",
      "Epoch 117/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4575 - recall: 0.7670 - val_loss: 0.4905 - val_recall: 0.7525\n",
      "Epoch 118/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4577 - recall: 0.7673 - val_loss: 0.4903 - val_recall: 0.7515\n",
      "Epoch 119/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4581 - recall: 0.7667 - val_loss: 0.4894 - val_recall: 0.7528\n",
      "Epoch 120/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4581 - recall: 0.7669 - val_loss: 0.4899 - val_recall: 0.7523\n",
      "Epoch 121/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4579 - recall: 0.7670 - val_loss: 0.4898 - val_recall: 0.7520\n",
      "Epoch 122/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4578 - recall: 0.7669 - val_loss: 0.4894 - val_recall: 0.7526\n",
      "Epoch 123/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4580 - recall: 0.7669 - val_loss: 0.4890 - val_recall: 0.7521\n",
      "Epoch 124/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4580 - recall: 0.7668 - val_loss: 0.4893 - val_recall: 0.7524\n",
      "Epoch 125/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4576 - recall: 0.7668 - val_loss: 0.4898 - val_recall: 0.7527\n",
      "Epoch 126/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4581 - recall: 0.7663 - val_loss: 0.4889 - val_recall: 0.7530\n",
      "Epoch 127/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4582 - recall: 0.7666 - val_loss: 0.4901 - val_recall: 0.7529\n",
      "Epoch 128/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4576 - recall: 0.7672 - val_loss: 0.4892 - val_recall: 0.7532\n",
      "Epoch 129/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4576 - recall: 0.7670 - val_loss: 0.4910 - val_recall: 0.7520\n",
      "Epoch 130/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4577 - recall: 0.7665 - val_loss: 0.4903 - val_recall: 0.7527\n",
      "Epoch 131/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4576 - recall: 0.7674 - val_loss: 0.4891 - val_recall: 0.7525\n",
      "Epoch 132/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4575 - recall: 0.7671 - val_loss: 0.4907 - val_recall: 0.7524\n",
      "Epoch 133/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4580 - recall: 0.7669 - val_loss: 0.4897 - val_recall: 0.7519\n",
      "Epoch 134/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4578 - recall: 0.7668 - val_loss: 0.4903 - val_recall: 0.7520\n",
      "Epoch 135/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4579 - recall: 0.7669 - val_loss: 0.4894 - val_recall: 0.7531\n",
      "Epoch 136/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4576 - recall: 0.7665 - val_loss: 0.4904 - val_recall: 0.7528\n",
      "Epoch 137/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4579 - recall: 0.7665 - val_loss: 0.4892 - val_recall: 0.7535\n",
      "Epoch 138/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4575 - recall: 0.7668 - val_loss: 0.4892 - val_recall: 0.7524\n",
      "Epoch 139/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4576 - recall: 0.7668 - val_loss: 0.4896 - val_recall: 0.7522\n",
      "Epoch 140/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4576 - recall: 0.7670 - val_loss: 0.4898 - val_recall: 0.7519\n",
      "Epoch 141/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4574 - recall: 0.7671 - val_loss: 0.4906 - val_recall: 0.7519\n",
      "Epoch 142/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4574 - recall: 0.7667 - val_loss: 0.4892 - val_recall: 0.7532\n",
      "Epoch 143/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4573 - recall: 0.7672 - val_loss: 0.4891 - val_recall: 0.7525\n",
      "Epoch 144/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4578 - recall: 0.7669 - val_loss: 0.4900 - val_recall: 0.7528\n",
      "Epoch 145/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4573 - recall: 0.7667 - val_loss: 0.4899 - val_recall: 0.7524\n",
      "Epoch 146/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4570 - recall: 0.7674 - val_loss: 0.4896 - val_recall: 0.7528\n",
      "Epoch 147/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4571 - recall: 0.7666 - val_loss: 0.4899 - val_recall: 0.7534\n",
      "Epoch 148/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4571 - recall: 0.7672 - val_loss: 0.4900 - val_recall: 0.7531\n",
      "Epoch 149/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4576 - recall: 0.7664 - val_loss: 0.4900 - val_recall: 0.7521\n",
      "Epoch 150/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4567 - recall: 0.7674 - val_loss: 0.4907 - val_recall: 0.7526\n",
      "Epoch 151/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4566 - recall: 0.7670 - val_loss: 0.4900 - val_recall: 0.7524\n",
      "Epoch 152/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4570 - recall: 0.7673 - val_loss: 0.4896 - val_recall: 0.7528\n",
      "Epoch 153/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4570 - recall: 0.7673 - val_loss: 0.4892 - val_recall: 0.7526\n",
      "Epoch 154/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4571 - recall: 0.7672 - val_loss: 0.4899 - val_recall: 0.7522\n",
      "Epoch 155/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4570 - recall: 0.7671 - val_loss: 0.4919 - val_recall: 0.7519\n",
      "Epoch 156/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4570 - recall: 0.7675 - val_loss: 0.4899 - val_recall: 0.7523\n",
      "Epoch 157/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4569 - recall: 0.7675 - val_loss: 0.4899 - val_recall: 0.7527\n",
      "Epoch 158/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4568 - recall: 0.7673 - val_loss: 0.4896 - val_recall: 0.7532\n",
      "Epoch 159/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4571 - recall: 0.7669 - val_loss: 0.4886 - val_recall: 0.7530\n",
      "Epoch 160/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4568 - recall: 0.7669 - val_loss: 0.4909 - val_recall: 0.7522\n",
      "Epoch 161/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4572 - recall: 0.7675 - val_loss: 0.4903 - val_recall: 0.7524\n",
      "Epoch 162/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4569 - recall: 0.7670 - val_loss: 0.4895 - val_recall: 0.7525\n",
      "Epoch 163/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4576 - recall: 0.7669 - val_loss: 0.4899 - val_recall: 0.7524\n",
      "Epoch 164/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4570 - recall: 0.7674 - val_loss: 0.4903 - val_recall: 0.7520\n",
      "Epoch 165/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4564 - recall: 0.7673 - val_loss: 0.4896 - val_recall: 0.7531\n",
      "Epoch 166/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4569 - recall: 0.7670 - val_loss: 0.4885 - val_recall: 0.7534\n",
      "Epoch 167/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4561 - recall: 0.7675 - val_loss: 0.4915 - val_recall: 0.7527\n",
      "Epoch 168/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4567 - recall: 0.7670 - val_loss: 0.4893 - val_recall: 0.7520\n",
      "Epoch 169/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4569 - recall: 0.7677 - val_loss: 0.4895 - val_recall: 0.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4566 - recall: 0.7676 - val_loss: 0.4902 - val_recall: 0.7533\n",
      "Epoch 171/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4565 - recall: 0.7670 - val_loss: 0.4885 - val_recall: 0.7537\n",
      "Epoch 172/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4564 - recall: 0.7673 - val_loss: 0.4893 - val_recall: 0.7531\n",
      "Epoch 173/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4570 - recall: 0.7674 - val_loss: 0.4893 - val_recall: 0.7531\n",
      "Epoch 174/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4569 - recall: 0.7673 - val_loss: 0.4900 - val_recall: 0.7523\n",
      "Epoch 175/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4566 - recall: 0.7674 - val_loss: 0.4913 - val_recall: 0.7525\n",
      "Epoch 176/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4568 - recall: 0.7673 - val_loss: 0.4903 - val_recall: 0.7526\n",
      "Epoch 177/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4560 - recall: 0.7680 - val_loss: 0.4899 - val_recall: 0.7526\n",
      "Epoch 178/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4560 - recall: 0.7676 - val_loss: 0.4909 - val_recall: 0.7513\n",
      "Epoch 179/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4567 - recall: 0.7675 - val_loss: 0.4882 - val_recall: 0.7522\n",
      "Epoch 180/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4564 - recall: 0.7677 - val_loss: 0.4891 - val_recall: 0.7527\n",
      "Epoch 181/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4561 - recall: 0.7678 - val_loss: 0.4888 - val_recall: 0.7526\n",
      "Epoch 182/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4562 - recall: 0.7675 - val_loss: 0.4889 - val_recall: 0.7528\n",
      "Epoch 183/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4569 - recall: 0.7675 - val_loss: 0.4891 - val_recall: 0.7522\n",
      "Epoch 184/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4563 - recall: 0.7674 - val_loss: 0.4895 - val_recall: 0.7523\n",
      "Epoch 185/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4558 - recall: 0.7674 - val_loss: 0.4905 - val_recall: 0.7524\n",
      "Epoch 186/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4560 - recall: 0.7674 - val_loss: 0.4894 - val_recall: 0.7527\n",
      "Epoch 187/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4563 - recall: 0.7672 - val_loss: 0.4896 - val_recall: 0.7531\n",
      "Epoch 188/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4561 - recall: 0.7673 - val_loss: 0.4902 - val_recall: 0.7528\n",
      "Epoch 189/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4562 - recall: 0.7677 - val_loss: 0.4895 - val_recall: 0.7531\n",
      "Epoch 190/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4564 - recall: 0.7675 - val_loss: 0.4898 - val_recall: 0.7528\n",
      "Epoch 191/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4561 - recall: 0.7676 - val_loss: 0.4899 - val_recall: 0.7525\n",
      "Epoch 192/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4563 - recall: 0.7672 - val_loss: 0.4885 - val_recall: 0.7531\n",
      "Epoch 193/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4559 - recall: 0.7677 - val_loss: 0.4899 - val_recall: 0.7528\n",
      "Epoch 194/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4561 - recall: 0.7677 - val_loss: 0.4908 - val_recall: 0.7525\n",
      "Epoch 195/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4565 - recall: 0.7678 - val_loss: 0.4906 - val_recall: 0.7518\n",
      "Epoch 196/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4560 - recall: 0.7678 - val_loss: 0.4896 - val_recall: 0.7529\n",
      "Epoch 197/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4560 - recall: 0.7677 - val_loss: 0.4904 - val_recall: 0.7521\n",
      "Epoch 198/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4559 - recall: 0.7679 - val_loss: 0.4898 - val_recall: 0.7529\n",
      "Epoch 199/200\n",
      "415211/415211 [==============================] - 2s 4us/step - loss: 0.4557 - recall: 0.7675 - val_loss: 0.4909 - val_recall: 0.7530\n",
      "Epoch 200/200\n",
      "415211/415211 [==============================] - 2s 5us/step - loss: 0.4559 - recall: 0.7678 - val_loss: 0.4904 - val_recall: 0.7526\n"
     ]
    }
   ],
   "source": [
    "history = ANN.fit(Xtrain, ytrain, validation_data=(Xtest, ytest), epochs=200, batch_size=10000, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIGrPP8YZgLy",
    "outputId": "1632fae7-5141-4a3e-910b-a7c551536a08"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['val_recall'])\n",
    "plt.title('model recall')\n",
    "plt.ylabel('recall')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkuXIrheZgL2",
    "outputId": "1ef73294-c052-494a-8be6-f2da960b64bf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Capstone2_model_building.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
